{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gcosma/COP509/blob/main/LabSolutions/Tips_for_Labs_1~7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lab Exercise (No. 1)**\n",
        "\n",
        "Tips:\n",
        "1. Use the dataset of *'Reduced_ArtsReviews_5000.txt'*."
      ],
      "metadata": {
        "id": "tKPynpWQHiGD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lab Exercise (No. 2)**\n",
        "\n",
        "Tips:\n",
        "1. Use *'ArtsReviews_5000_train.txt'* and *'ArtsRatings_5000_train.txt'* for tarining;\n",
        "\n",
        "   Use *'ArtsReviews_5000_test.txt'* and and *'ArtsRatings_5000_test.txt'* for test.\n",
        "2. Different from the tutorial (each txt file is a review), each line of the txt file used by this lab exrcise is a review, thus you may need to read the txt file as lines.\n",
        "3. You may need ***from keras.utils.np_utils import to_categorical*** to convert the labels (Ratings).\n",
        "\n",
        "   Notice: Ratings start from **1** to **5**, but the result of ***to_categorical()*** starts from **0**. Therefore, every Rating label needs to be decreased with **1** if training and testing, and the result of prediction needs to be increased with **1**."
      ],
      "metadata": {
        "id": "2ucmyQemHraz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lab Exercise (No. 3)**\n",
        "\n",
        "Tips:\n",
        "1. Use *'ArtsReviews_5000_train.txt'* and *'ArtsRatings_5000_train.txt'* for tarining;\n",
        "\n",
        "   Use *'ArtsReviews_5000_test.txt'* and and *'ArtsRatings_5000_test.txt'* for test.\n",
        "2. You may need ***from keras.utils.np_utils import to_categorical*** to convert the labels (Ratings).\n",
        "3. Do not forget clean the reviews with **lowercase**, otherwise, you may get an error on using word2vector embeddings for classification."
      ],
      "metadata": {
        "id": "AJ8k_BHpH5Id"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lab Exercise (No. 4a)**\n",
        "\n",
        "Tips:\n",
        "\n",
        "1. Use the dataset of *'Reduced_ArtsReviews_5000.txt'*."
      ],
      "metadata": {
        "id": "6disFASMH4_D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lab Exercise (No. 4b)**\n",
        "\n",
        "Tips:\n",
        "\n",
        "1. Use the dataset of *'Reduced_ArtsReviews_5000.txt'*.\n",
        "2. You can program for computing *Recall*, *Precision*, and *F1-measure* and ploting *Recall/Precision curves*.\n",
        "3. The order of the Review in the file is the ID of the Review (Notice: order starts from 1 to 5000.). The two queries and their relevant Reviews' ID are given as following:\n",
        "\n",
        "   Querys = ['The pen is good.', 'The pen is poor.']\n",
        "\n",
        "   Relevant_ID = [[24,337,500,959,1346,1537,1746,1761,1892,2128,2185,2339,2603,3161,3181,3192,3202,3627,3796,4161,4293,4678,4758,4790,4798],\n",
        "[224,353,368,415,462,571,856,880,903,906,1377,1532,1784,1901,2061,2690,2719,3380,3925,4164,4279,4833,4852]]"
      ],
      "metadata": {
        "id": "_hnRYRFUH42A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lab Exercise (No. 5)**\n",
        "\n",
        "Tips:\n",
        "1. Use the top **500** data of *'ArtsReviews_5000_train.txt'* and *'ArtsRatings_5000_train.txt'* for tarining;\n",
        "\n",
        "   Use the top **500** data 'ArtsReviews_5000_test.txt'* and and *'ArtsRatings_5000_test.txt'* for test."
      ],
      "metadata": {
        "id": "QM6wFIW0H4uN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lab Exercise (No. 6)**\n",
        "\n",
        "Tips:\n",
        "1. Use the top **10** reviews of *'Reduced_ArtsReviews_5000.txt'*.\n",
        "2. The ground truth for evaluation is given as follows:\n",
        "\n",
        "targets = ['the product is overpriced'\n",
        "           ' the price should be significantly lower ',\n",
        "           'They came packed/coated with a yellowish oil, like mild steel tools often are.'\n",
        "           'The description didn\\'t specify the materials',\n",
        "           'GREAT buy!'\n",
        "           'I now have two of these',\n",
        "           'Still having problems getting the upper tension correct.',\n",
        "           'The Velcro bottom would not stick to the place I wanted it to.',\n",
        "           'The \"Best Pals\" card can be found for under $99, so if you want to most designs possible, it might be a better buy.',\n",
        "           'I bought this candle. It was NOT clear.',\n",
        "           'This would indicate that it was mismarked, and lower than 14k gold.',\n",
        "           'I needed more yarn to finish a baby blanket.',\n",
        "           'Unfortunately the extra broad nib was cracked and leaked all over.']"
      ],
      "metadata": {
        "id": "gOnIhEBLH4mW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lab Exercise (No. 7)**\n",
        "\n",
        "Tips:\n",
        "1. Use the top **10** reviews of *'Reduced_ArtsReviews_5000.txt'*."
      ],
      "metadata": {
        "id": "oeXkNa85H4dS"
      }
    }
  ]
}